import asyncio
from tqdm.asyncio import tqdm
from playwright.async_api import async_playwright
from urllib.parse import urljoin
import logging
import time
from typing import Optional
from datetime import timedelta
from fake_useragent import UserAgent
import argparse
import sys
import tqdm

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def setup_logging(log_file=None):
    handlers = [logging.StreamHandler(sys.stdout)]
    if log_file:
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=handlers
    )
    logging.getLogger('playwright').setLevel(logging.WARNING)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
BASE_URL = "https://lombard-perspectiva.ru"
try:
    USER_AGENT = UserAgent().random
except Exception:
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"

MAX_CONCURRENT_TASKS = 10
REQUEST_TIMEOUT = 10_000  # 2 –º–∏–Ω
HEADLESS = True
VIEWPORT = {'width': 600, 'height': 400}
PROXY = None  # –ø—Ä–∏–º–µ—Ä: "http://login:pass@ip:port"

class ParserTimer:
    def __init__(self):
        self.start_time = None

    def start(self):
        self.start_time = time.perf_counter()
        logger.info("‚è± –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")

    def stop(self):
        return time.perf_counter() - self.start_time

async def block_resources(route):
    # 'image'
    if route.request.resource_type in {'stylesheet', 'font'}:
        await route.abort()
    else:
        await route.continue_()

async def get_product_data(context, url: str, semaphore: asyncio.Semaphore) -> Optional[dict]:
    async with semaphore:
        page = await context.new_page()
        try:
            # await page.route('**/*.{png,jpg,jpeg,webp,svg,gif,css,woff2}', block_resources)
            await page.goto(url, wait_until="domcontentloaded", timeout=15000)
        #     logger.info("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        # except Exception as e:
        #     logger.error(f"‚ùå GOTO –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è: {e}")
        # try:
            await page.wait_for_selector('img[itemprop="image"]', timeout=15000)

            product_data = await page.evaluate('''() => {
                const h1 = document.querySelector('h1[itemprop="name"]');
                const img = document.querySelector('img[itemprop="image"]');
                if (!h1 || !img) return null;

                const src = img.currentSrc || img.src || img.getAttribute('data-src') || '';

                return {
                    name: h1.textContent.trim(),
                    url: window.location.href,
                    image: src
                };
            }''')

            # –ü–æ–¥—Å—á—ë—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

            if product_data:
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {product_data['name'][:30]}...")
                return product_data
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ ({url[-15:]}): {str(e)[:50]}...")
            return None
        finally:
            await page.close()

async def get_product_links(page, page_num: int, retries=3) -> list:
    url = f"{BASE_URL}/clocks_today/?page={page_num}"
    logger.info(f"üåê –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")

    for attempt in range(retries):
        try:
            await page.goto(url, wait_until="domcontentloaded", timeout=REQUEST_TIMEOUT)
            await page.wait_for_selector('a.product-list-item', timeout=15000)

            if await page.query_selector('div#recaptcha'):
                raise Exception("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞")

            links = await page.evaluate('''() =>
                Array.from(document.querySelectorAll('a.product-list-item'))
                    .map(a => a.href)
                    .filter(Boolean)
            ''')

            found_links = [urljoin(BASE_URL, link) for link in links if link]
            logger.info(f"üîó –ù–∞–π–¥–µ–Ω–æ {len(found_links)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            return found_links

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            if attempt == retries - 1:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                return []

async def parse_products_page(page_num: int, items_limit: int = None, on_progress=None):
    timer = ParserTimer()
    timer.start()

    async with async_playwright() as p:
        launch_args = {
            "headless": HEADLESS,
            "args": [
                "--disable-blink-features=AutomationControlled",
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-gpu",
            ]
        }
        if PROXY:
            launch_args["proxy"] = {"server": PROXY}

        browser = await p.chromium.launch(**launch_args)
        context = await browser.new_context(
            user_agent=USER_AGENT,
            java_script_enabled=True,
            ignore_https_errors=True,
            viewport=VIEWPORT,
            locale='ru-RU',
        )

        main_page = await context.new_page()
        try:
            product_links = await get_product_links(main_page, page_num)
            if items_limit:
                product_links = product_links[:items_limit]

            semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
            # –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –ø–æ —Å—Å—ã–ª–∫–∞–º
            tasks = [get_product_data(context, link, semaphore) for link in product_links]
            # tqdm.gather(*tasks) –∑–∞–º–µ–Ω—è–µ—Ç –æ–±—ã—á–Ω—ã–π asyncio.gather, –Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å.
            # ncols=80 ‚Äî —à–∏—Ä–∏–Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞, –º–æ–∂–µ—à—å –ø–æ–¥–æ–≥–Ω–∞—Ç—å –ø–æ–¥ –∫–æ–Ω—Å–æ–ª—å.
            # desc ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.
            try:
                results_raw = await asyncio.gather(*tasks)
                # results_raw = await tqdm.gather(*tasks, desc="üì¶ –ü–∞—Ä—Å–∏–Ω–≥", ncols=80)
            except RuntimeError as e:
                logger.warning(f"Async error (interpreter shutdown?): {e}")
                results_raw = []
            # result_raw = await tqdm.gather(*tasks, desk="–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤", ncols=80)

            results = [r for r in results_raw if r]

            elapsed = timer.stop()
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {len(results)} —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞ {timedelta(seconds=elapsed)}")
            return results

        except Exception as e:
            logger.error(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}")
            return []

        finally:
            await main_page.close()
            await context.close()
            await browser.close()

async def cli_main(args):
    setup_logging(args.log_file)

    try:
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {args.page}, –ª–∏–º–∏—Ç {args.limit}")
        results = await parse_products_page(page_num=args.page, items_limit=args.limit)

        print("\n" + "=" * 50)
        print(f"–í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for i, item in enumerate(results[:5], 1):
            print(f"""{i}.
            <div class="catalog-item">
              <img src="{item['image']}" alt="{item['name']}" loading="lazy" itemprop="image" class="catalog-item-img--object">
              <h3>{item['name']}</h3>
              <a href="{item['url']}">–°–º–æ—Ç—Ä–µ—Ç—å</a>
            </div>""")
        # {item['name']} - {item['url']}")
        # if len(results) > 5:
        #     print(f"... –∏ –µ—â–µ {len(results) - 5} —Ç–æ–≤–∞—Ä–æ–≤")
        # print("=" * 50 + "\n")

        return 0

    except Exception as e:
        logger.error(f"üí• –û—à–∏–±–∫–∞: {str(e)}", exc_info=True)
        return 1
    finally:
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞")

def parse_cli_args():
    parser = argparse.ArgumentParser(
        description="üïµÔ∏è –ü–∞—Ä—Å–µ—Ä —Å–∞–π—Ç–∞ lombard-perspectiva.ru",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument('--page', type=int, default=1, help='–ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞')
    parser.add_argument('--limit', type=int, default=None, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞')
    parser.add_argument('--log-file', type=str, default=None, help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    return parser.parse_args()

if __name__ == "__main__":
    setup_logging()
    args = parse_cli_args()
    sys.exit(asyncio.run(cli_main(args)))
